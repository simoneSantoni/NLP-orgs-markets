{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Session 3, part I\n",
    "\n",
    "## Vector semantics and embeddings\n",
    "\n",
    "<img src=\"images/0.jpg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Learning goals\n",
    "============\n",
    "\n",
    "\n",
    "- Appreciating the anatomy of word2vec\n",
    "- Assigning a role to new forms of embeddings\n",
    "- Understanding the various steps to train ad hoc embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Week 2: Key tenets\n",
    "================\n",
    "\n",
    "+ modern NLP ~ Distributional Hypothesis + DL\n",
    "+ words can be represented as vectors (Lenci 2018)\n",
    "+ desiderata: by observing and analyzing a same word in multiple context, we aim at:\n",
    "  - building a *dense, real-value* vector for each word\n",
    "  - ... chosen so that it is similar to vectors of words that appear in similar contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Word vectors as dense, real valued vectors\n",
    "===================================\n",
    "\n",
    "Ultimately, by observing and analyzing a same word in multiple context, we aim at building a dense vector for each word, chosen so that it is similar to vectors of words that appear in similar contexts.\n",
    "\n",
    "Below is a portion of the [vector](https://spacy.io/usage/vectors-similarity) associated with the word 'banana'.\n",
    "\n",
    "```\n",
    "array([2.02280000e-01,  -7.66180009e-02,   3.70319992e-01,\n",
    "       3.28450017e-02,  -4.19569999e-01,   7.20689967e-02,\n",
    "      -3.74760002e-01,   5.74599989e-02,  -1.24009997e-02,\n",
    "       5.29489994e-01,  -5.23800015e-01,  -1.97710007e-01,\n",
    "      -3.41470003e-01,   5.33169985e-01,  -2.53309999e-02,\n",
    "       1.73800007e-01,   1.67720005e-01,   8.39839995e-01,\n",
    "       5.51070012e-02,   1.05470002e-01,   3.78719985e-01,\n",
    "       2.42750004e-01,   1.47449998e-02,   5.59509993e-01,\n",
    "       1.25210002e-01,  -6.75960004e-01,   3.58420014e-01,\n",
    "       # ... and so on ...\n",
    "       3.66849989e-01,   2.52470002e-03,  -6.40089989e-01,\n",
    "      -2.97650009e-01,   7.89430022e-01,   3.31680000e-01,\n",
    "      -1.19659996e+00,  -4.71559986e-02,   5.31750023e-01], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How to retrieve word vectors from a pre-trained model of the language?\n",
    "========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0228e-01, -7.6618e-02,  3.7032e-01,  3.2845e-02, -4.1957e-01,\n",
       "        7.2069e-02, -3.7476e-01,  5.7460e-02, -1.2401e-02,  5.2949e-01,\n",
       "       -5.2380e-01, -1.9771e-01, -3.4147e-01,  5.3317e-01, -2.5331e-02,\n",
       "        1.7380e-01,  1.6772e-01,  8.3984e-01,  5.5107e-02,  1.0547e-01,\n",
       "        3.7872e-01,  2.4275e-01,  1.4745e-02,  5.5951e-01,  1.2521e-01,\n",
       "       -6.7596e-01,  3.5842e-01, -4.0028e-02,  9.5949e-02, -5.0690e-01,\n",
       "       -8.5318e-02,  1.7980e-01,  3.3867e-01,  1.3230e-01,  3.1021e-01,\n",
       "        2.1878e-01,  1.6853e-01,  1.9874e-01, -5.7385e-01, -1.0649e-01,\n",
       "        2.6669e-01,  1.2838e-01, -1.2803e-01, -1.3284e-01,  1.2657e-01,\n",
       "        8.6723e-01,  9.6721e-02,  4.8306e-01,  2.1271e-01, -5.4990e-02,\n",
       "       -8.2425e-02,  2.2408e-01,  2.3975e-01, -6.2260e-02,  6.2194e-01,\n",
       "       -5.9900e-01,  4.3201e-01,  2.8143e-01,  3.3842e-02, -4.8815e-01,\n",
       "       -2.1359e-01,  2.7401e-01,  2.4095e-01,  4.5950e-01, -1.8605e-01,\n",
       "       -1.0497e+00, -9.7305e-02, -1.8908e-01, -7.0929e-01,  4.0195e-01,\n",
       "       -1.8768e-01,  5.1687e-01,  1.2520e-01,  8.4150e-01,  1.2097e-01,\n",
       "        8.8239e-02, -2.9196e-02,  1.2151e-03,  5.6825e-02, -2.7421e-01,\n",
       "        2.5564e-01,  6.9793e-02, -2.2258e-01, -3.6006e-01, -2.2402e-01,\n",
       "       -5.3699e-02,  1.2022e+00,  5.4535e-01, -5.7998e-01,  1.0905e-01,\n",
       "        4.2167e-01,  2.0662e-01,  1.2936e-01, -4.1457e-02, -6.6777e-01,\n",
       "        4.0467e-01, -1.5218e-02, -2.7640e-01, -1.5611e-01, -7.9198e-02,\n",
       "        4.0037e-02, -1.2944e-01, -2.4090e-04, -2.6785e-01, -3.8115e-01,\n",
       "       -9.7245e-01,  3.1726e-01, -4.3951e-01,  4.1934e-01,  1.8353e-01,\n",
       "       -1.5260e-01, -1.0808e-01, -1.0358e+00,  7.6217e-02,  1.6519e-01,\n",
       "        2.6526e-04,  1.6616e-01, -1.5281e-01,  1.8123e-01,  7.0274e-01,\n",
       "        5.7956e-03,  5.1664e-02, -5.9745e-02, -2.7551e-01, -3.9049e-01,\n",
       "        6.1132e-02,  5.5430e-01, -8.7997e-02, -4.1681e-01,  3.2826e-01,\n",
       "       -5.2549e-01, -4.4288e-01,  8.2183e-03,  2.4486e-01, -2.2982e-01,\n",
       "       -3.4981e-01,  2.6894e-01,  3.9166e-01, -4.1904e-01,  1.6191e-01,\n",
       "       -2.6263e+00,  6.4134e-01,  3.9743e-01, -1.2868e-01, -3.1946e-01,\n",
       "       -2.5633e-01, -1.2220e-01,  3.2275e-01, -7.9933e-02, -1.5348e-01,\n",
       "        3.1505e-01,  3.0591e-01,  2.6012e-01,  1.8553e-01, -2.4043e-01,\n",
       "        4.2886e-02,  4.0622e-01, -2.4256e-01,  6.3870e-01,  6.9983e-01,\n",
       "       -1.4043e-01,  2.5209e-01,  4.8984e-01, -6.1067e-02, -3.6766e-01,\n",
       "       -5.5089e-01, -3.8265e-01, -2.0843e-01,  2.2832e-01,  5.1218e-01,\n",
       "        2.7868e-01,  4.7652e-01,  4.7951e-02, -3.4008e-01, -3.2873e-01,\n",
       "       -4.1967e-01, -7.5499e-02, -3.8954e-01, -2.9622e-02, -3.4070e-01,\n",
       "        2.2170e-01, -6.2856e-02, -5.1903e-01, -3.7774e-01, -4.3477e-03,\n",
       "       -5.8301e-01, -8.7546e-02, -2.3929e-01, -2.4711e-01, -2.5887e-01,\n",
       "       -2.9894e-01,  1.3715e-01,  2.9892e-02,  3.6544e-02, -4.9665e-01,\n",
       "       -1.8160e-01,  5.2939e-01,  2.1992e-01, -4.4514e-01,  3.7798e-01,\n",
       "       -5.7062e-01, -4.6946e-02,  8.1806e-02,  1.9279e-02,  3.3246e-01,\n",
       "       -1.4620e-01,  1.7156e-01,  3.9981e-01,  3.6217e-01,  1.2816e-01,\n",
       "        3.1644e-01,  3.7569e-01, -7.4690e-02, -4.8480e-02, -3.1401e-01,\n",
       "       -1.9286e-01, -3.1294e-01, -1.7553e-02, -1.7514e-01, -2.7587e-02,\n",
       "       -1.0000e+00,  1.8387e-01,  8.1434e-01, -1.8913e-01,  5.0999e-01,\n",
       "       -9.1960e-03, -1.9295e-03,  2.8189e-01,  2.7247e-02,  4.3409e-01,\n",
       "       -5.4967e-01, -9.7426e-02, -2.4540e-01, -1.7203e-01, -8.8650e-02,\n",
       "       -3.0298e-01, -1.3591e-01, -2.7765e-01,  3.1286e-03,  2.0556e-01,\n",
       "       -1.5772e-01, -5.2308e-01, -6.4701e-01, -3.7014e-01,  6.9393e-02,\n",
       "        1.1401e-01,  2.7594e-01, -1.3875e-01, -2.7268e-01,  6.6891e-01,\n",
       "       -5.6454e-02,  2.4017e-01, -2.6730e-01,  2.9860e-01,  1.0083e-01,\n",
       "        5.5592e-01,  3.2849e-01,  7.6858e-02,  1.5528e-01,  2.5636e-01,\n",
       "       -1.0772e-01, -1.2359e-01,  1.1827e-01, -9.9029e-02, -3.4328e-01,\n",
       "        1.1502e-01, -3.7808e-01, -3.9012e-02, -3.4593e-01, -1.9404e-01,\n",
       "       -3.3580e-01, -6.2334e-02,  2.8919e-01,  2.8032e-01, -5.3741e-01,\n",
       "        6.2794e-01,  5.6955e-02,  6.2147e-01, -2.5282e-01,  4.1670e-01,\n",
       "       -1.0108e-02, -2.5434e-01,  4.0003e-01,  4.2432e-01,  2.2672e-01,\n",
       "        1.7553e-01,  2.3049e-01,  2.8323e-01,  1.3882e-01,  3.1218e-03,\n",
       "        1.7057e-01,  3.6685e-01,  2.5247e-03, -6.4009e-01, -2.9765e-01,\n",
       "        7.8943e-01,  3.3168e-01, -1.1966e+00, -4.7156e-02,  5.3175e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['banana'].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Why dense, real-valued vectors rather than sparse vectors?\n",
    "=================================================\n",
    "\n",
    "+ convenience: in ML, you don't want to deal with thousands of features \n",
    "+ they may do better at capturing synonymy/semantic similarity:\n",
    "  - 'car' and 'automobile' are synonyms; but are distinct dimensions\n",
    "  - a word with 'car' as a neighbor and a word with 'automobile' as a neighbor should be similar, but aren't\n",
    "+ in practice, they work better\n",
    "\n",
    "Notes. ― The materials included in the following slides are based on Jurafsky and Martin's book 'Speech and Language Processing and Speech Recognition' (chapter 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Examples of word-vectors and embeddings\n",
    "===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### [$\\texttt{word2vec}$](https://code.google.com/archive/p/word2vec/) ― the pioneer\n",
    "\n",
    "<img src=\"images/_1.png\" width=\"15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### [**Fasttext**](http://www.fasttext.cc/) ― it takes word parts into account\n",
    "\n",
    "<img src=\"images/_2.png\" width=\"6%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### [**GloVe**](http://nlp.stanford.edu/projects/glove/) ― it emphasizes co-occurrences of words in the whole text corpus\n",
    "\n",
    "<img src=\"images/_3.png\" width=\"22%\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
